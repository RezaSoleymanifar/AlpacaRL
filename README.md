<div align="center">
<img align="center" src=figs/alpacarl.jpg width="100%"/>
</div>

[![Downloads](https://pepy.tech/badge/finrl)](https://pepy.tech/project/finrl)
[![Downloads](https://pepy.tech/badge/finrl/week)](https://pepy.tech/project/finrl)
[![Python 3.6](https://img.shields.io/badge/python-3.6-blue.svg)](https://www.python.org/downloads/release/python-360/)
[![PyPI](https://img.shields.io/pypi/v/finrl.svg)](https://pypi.org/project/finrl/)
[![Documentation Status](https://readthedocs.org/projects/finrl/badge/?version=latest)](https://finrl.readthedocs.io/en/latest/?badge=latest)
![License](https://img.shields.io/github/license/AI4Finance-Foundation/finrl.svg?color=brightgreen)

# AlpacaRL
AlpacaRL is a deep reinforcement learning library for high frequency stocks and crypto trading in Alpaca API. AlpacaRL offers end-to-end suport from development to deployment of custom tailored algorithms. Stable versions of state of the art DRL algorithms are implemented using PyTorch and stable-baselines3. AlpacaRL offers a minimalist pythonic interface that enables users to focus on rapid testing, and prototyping. Environment design, preprossing, feature engineering, reward shaping, and model configuration procedures are encapsulated allowing user to focus on atomic components without continuity concerns or boilerplate code.

Example showing how you can achieve required configurations of DRL algorithms specified in their original papers: